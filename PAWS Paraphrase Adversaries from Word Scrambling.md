### [PAWS: Paraphrase Adversaries from Word Scrambling](https://arxiv.org/pdf/1904.01130.pdf)

- Emphasize the collection of **challenging negative examples.**
- Pairs have a large BOW overlap
- A Dataset with 108,463 well formed paraphrase and non-paraphrase pairs with high lexical overlap. 
- Challenging pairs are generated by controlled **word swapping** and **back translation, followed by fluency and paraphrase judgments by human raters.**
- State of-the-art models trained on existing datasets have dismal performance on PAWS (<40% accuracy); however, including PAWS training data for these models improves their accuracy to 85% while maintaining performance on existing tasks.
- Unlike BERT, a simple BOW model fails to learn from PAWS training examples, demonstrating its weakness at capturing non-local contextual information